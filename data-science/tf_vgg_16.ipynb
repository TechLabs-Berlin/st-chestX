{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_vgg_16.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Wjyq6XjRiifn"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak1SzqPmicoD"
      },
      "source": [
        "# Data Split "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5OMPO7OR7US",
        "outputId": "d37289f4-e809-4f3c-a189-c9ed5a2bb391"
      },
      "source": [
        "\n",
        "#https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from  matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "import itertools\n",
        "import glob\n",
        "import shutil\n",
        "import os\n",
        "from random import shuffle\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsobZPceR3Gf"
      },
      "source": [
        "data_path = '/content/covid_data/COVID-19_Radiography_Dataset'\n",
        "covid_img_path = \"/content/covid_data/COVID-19_Radiography_Dataset/COVID\"\n",
        "normal_img_path = \"/content/covid_data/COVID-19_Radiography_Dataset/Normal\"\n",
        "\n",
        "\n",
        "\n",
        "normal_train_path = '/content/img/train/normal'\n",
        "normal_test_path = '/content/img/test/normal' \n",
        "normal_val_path =  '/content/img/val/normal'\n",
        "\n",
        "covid_train_path = '/content/img/train/covid'\n",
        "covid_test_path = '/content/img/test/covid' \n",
        "covid_val_path =  '/content/img/val/covid'\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/archive.zip'\n",
        "data_path = \"/content/covid_data\"\n",
        "\n",
        "checkpoints_path = \"/content/img/model/checkpoints\"\n",
        "\n",
        "if not os.path.exists(data_path):\n",
        "  os.mkdir(data_path)  \n",
        "  os.mkdir('/content/img')\n",
        "  os.mkdir('/content/img/train')\n",
        "  os.mkdir('/content/img/test')\n",
        "  os.mkdir('/content/img/val')\n",
        "\n",
        "  os.mkdir('/content/img/train/covid')\n",
        "  os.mkdir('/content/img/test/covid')\n",
        "  os.mkdir('/content/img/val/covid')\n",
        "\n",
        "  os.mkdir('/content/img/train/normal')\n",
        "  os.mkdir('/content/img/test/normal')\n",
        "  os.mkdir('/content/img/val/normal')\n",
        "  #os.mkdir(\"/content/img/model/checkpoints\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if not os.path.exists(\"/content/img/model\"):\n",
        "  os.mkdir(\"/content/img/model\")\n",
        "  os.mkdir(\"/content/img/model/checkpoints\")\n",
        "\n",
        "\n",
        "checkpoints_path = \"/content/img/model/checkpoints\"\n",
        "model_path = \"/content/img/model\"\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(data_path)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxXk_ZJsordu"
      },
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "for i in range(5):\n",
        "  file = random.choice(os.listdir(covid_img_path))\n",
        "  image_path = os.path.join( covid_img_path,file)\n",
        "  img = mpimg.imread(image_path)\n",
        "  ax = plt.subplot(1,5,i+1)\n",
        "  plt.imshow(img)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynkR4I-AO3Kc"
      },
      "source": [
        "covid_image_list = os.listdir(covid_img_path)\n",
        "covid_image_length = len(covid_image_list)\n",
        "\n",
        "\n",
        "normal_image_list = os.listdir(normal_img_path)\n",
        "normal_image_length = len(normal_image_list)\n",
        "\n",
        "\n",
        "covid_train_split = int(.7 * covid_image_length)\n",
        "covid_test_split = int(.15 * covid_image_length)\n",
        "covid_val_split = int(.15 * covid_image_length)\n",
        "\n",
        "normal_train_split = int(.7 * normal_image_length)\n",
        "normal_test_split = int(.15 * normal_image_length)\n",
        "normal_val_split = int(.15 * normal_image_length)\n",
        "\n",
        "\n",
        "random.seed(4)\n",
        "random.shuffle(covid_image_list)\n",
        "random.shuffle(normal_image_list)\n",
        "covid_val_images = covid_image_list[:covid_val_split]\n",
        "covid_test_images = covid_image_list[covid_val_split:covid_val_split*2]\n",
        "covid_train_images = covid_image_list[covid_val_split*2:]\n",
        "\n",
        "normal_val_images = normal_image_list[:normal_val_split]\n",
        "normal_test_images = normal_image_list[normal_val_split:normal_val_split*2]\n",
        "normal_train_images = normal_image_list[normal_val_split*2:]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q12NB9a4jklH"
      },
      "source": [
        "for image in normal_train_images:\n",
        "  \n",
        "  shutil.copy(os.path.join(normal_img_path ,image), '/content/img/train/normal' )\n",
        "\n",
        "for image in normal_test_images:\n",
        "  \n",
        "  shutil.copy(os.path.join(normal_img_path ,image), '/content/img/test/normal' )\n",
        "\n",
        "for image in normal_val_images:\n",
        "  \n",
        "  shutil.copy(os.path.join(normal_img_path ,image), '/content/img/val/normal' )\n",
        "\n",
        "for image in covid_test_images:\n",
        "  \n",
        "  shutil.copy(os.path.join(covid_img_path ,image), '/content/img/test/covid' )\n",
        "\n",
        "for image in covid_train_images:\n",
        "  \n",
        "  shutil.copy(os.path.join(covid_img_path ,image), '/content/img/train/covid' )\n",
        "\n",
        "for image in covid_val_images:\n",
        "  \n",
        "  shutil.copy(os.path.join(covid_img_path ,image), '/content/img/val/covid' )\n",
        "\n",
        "            "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6_L4lJ2vj_y"
      },
      "source": [
        "# tf.dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqH2kx6dzK_G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "d713f098-c542-4838-bf0f-dc7dfb71f7bc"
      },
      "source": [
        "#Questions:\n",
        "'''\n",
        "-next steps after improvements?\n",
        "-when do i read the images (as img) w PILL or cv2? if i have to\n",
        "-im trying to understand what is\n",
        "  batch[0].shape \n",
        "  (18, 256, 256, 1)\n",
        "  and how will this affect model training\n",
        "\n",
        "-how to display images from imagedatagenerator\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "#https://keras.io/api/preprocessing/image/\n",
        "\n",
        "\n",
        "#https://www.analyticsvidhya.com/blog/2020/11/extending-the-imagedatagenerator-keras-tensorflow/\n",
        "# target size\n",
        "\n",
        "\n",
        "#https://stats.stackexchange.com/questions/111467/is-it-necessary-to-scale-the-target-value-in-addition-to-scaling-features-for-re\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n-next steps after improvements?\\n-when do i read the images (as img) w PILL or cv2? if i have to\\n-im trying to understand what is\\n  batch[0].shape \\n  (18, 256, 256, 1)\\n  and how will this affect model training\\n\\n-how to display images from imagedatagenerator\\n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGeMMzNEsPVF"
      },
      "source": [
        "train_path = \"/content/img/train\"\n",
        "test_path = \"/content/img/test\"\n",
        "val_path = \"/content/img/val\"\n",
        "batch_size = 18\n",
        "img_size = 224\n",
        "input_path = \"/content/img\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFJw2ycLvn4c"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#no data aug now\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "#no img_aug for now\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "# Note that the validation data should not be augmented!\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qku0OwOrwzJ",
        "outputId": "2629f151-63fe-414c-bdf8-01c7116710a5"
      },
      "source": [
        "train_flow = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size = (224, 224),    \n",
        "    subset='training',\n",
        "    shuffle=True,\n",
        "    color_mode=\"rgb\",\n",
        "    class_mode = 'binary',\n",
        "    batch_size = batch_size,    \n",
        "    #? why this size? some 299, 96\n",
        "    )\n",
        "\n",
        "\n",
        "test_flow = test_datagen.flow_from_directory(\n",
        "        \n",
        "    test_path,\n",
        "    target_size = (224, 224),#? what size?\n",
        "    #subset='validation',\n",
        "    shuffle=True,\n",
        "    color_mode=\"rgb\",\n",
        "    class_mode = 'binary',\n",
        "    batch_size = batch_size\n",
        "    )\n",
        "\n",
        "val_flow = val_datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size = (224, 224),#? what size?\n",
        "    color_mode=\"rgb\",\n",
        "    class_mode = 'binary',\n",
        "    batch_size = batch_size   \n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9668 images belonging to 2 classes.\n",
            "Found 2070 images belonging to 2 classes.\n",
            "Found 2070 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL72GWoGFTTT"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4NJEOkLFTVl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSXFz3xgFTXv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAcb6I6LFTZo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAMPxn_bFTbn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-Sg7hhSAJ_z",
        "outputId": "904b07d2-03ae-4e4c-ef33-5749d5638412"
      },
      "source": [
        "next(train_flow)[0].shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq_VlDDuwFn2"
      },
      "source": [
        "#ready to train....?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjyq6XjRiifn"
      },
      "source": [
        "#tf.Records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjsUC49WruM2"
      },
      "source": [
        "#https://www.kaggle.com/hitarthhshah/covid19-detection-with-rnn\n",
        "\n",
        "'''\n",
        "\n",
        "normal_train_path = '/content/img/train/normal'\n",
        "normal_test_path = '/content/img/test/normal' \n",
        "normal_val_path =  '/content/img/val/normal'\n",
        "\n",
        "covid_train_path = '/content/img/train/covid'\n",
        "covid_test_path = '/content/img/test/covid' \n",
        "covid_val_path =  '/content/img/val/covid'\n",
        "train_path = \"/content/img/train\"\n",
        "test_path = \"/content/img/test\"\n",
        "val_path = \"/content/img/val\"\n",
        "\n",
        "data_path = /content/covid_data\n",
        "covid_img_path = \"/content/covid_data/COVID-19_Radiography_Dataset/COVID\"\n",
        "normal_img_path = \"/content/covid_data/COVID-19_Radiography_Dataset/Normal\"\n",
        "\n",
        "covid_train_split = int(.7 * covid_image_length)\n",
        "covid_test_split = int(.15 * covid_image_length)\n",
        "covid_val_split = int(.15 * covid_image_length)\n",
        "\n",
        "normal_train_split = int(.7 * normal_image_length)\n",
        "normal_test_split = int(.15 * normal_image_length)\n",
        "normal_val_split = int(.15 * normal_image_length)\n",
        "\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgLUb8AgEAuy"
      },
      "source": [
        "def read_directory():\n",
        "    filenames = []\n",
        "    labels = []\n",
        "    covid_files_dir = data_path + 'COVID-19'\n",
        "    normal_files_dir = data_path + 'NORMAL'\n",
        "    \n",
        "    for filename in os.listdir(covid_img_path):\n",
        "      filenames.append(\"/content/covid_data/COVID-19_Radiography_Dataset/COVID/\" + filename)\n",
        "      labels.append(0)\n",
        "\n",
        "    \n",
        "    for filename in os.listdir(normal_img_path):\n",
        "      filenames.append(\"/content/covid_data/COVID-19_Radiography_Dataset/Normal/\" + filename)  \n",
        "      labels.append(1) \n",
        "    \n",
        "        ###\n",
        "    labelled_filenames = list(zip(filenames,labels))#\n",
        "    data_size = len(filenames)#\n",
        "    training_data_size = int(data_size * 0.7)#\n",
        "    random.shuffle(labelled_filenames)#\n",
        "    val_list = labelled_filenames[:testing_data_size]\n",
        "    testing_list = labelled_filenames[testing_data_size:testing_data_size*2]#!\n",
        "    training_list = labelled_filenames[testing_data_size*2:]#!\n",
        "\n",
        "    training_filenames, training_labels = zip(*training_list)\n",
        "    testing_filenames, testing_labels = zip(*testing_list)\n",
        "\n",
        "    return training_filenames, training_labels, testing_filenames, testing_labels\n",
        "    ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhwK3EhVldbn"
      },
      "source": [
        "labelled_filenames = list(zip(filenames,labels))#\n",
        "data_size = len(filenames)#\n",
        "training_data_size = int(data_size * 0.7)#\n",
        "testing_data_size = int(data_size*.15)\n",
        "\n",
        "random.shuffle(labelled_filenames)#\n",
        "\n",
        "val_list = labelled_filenames[:testing_data_size]\n",
        "testing_list = labelled_filenames[testing_data_size:testing_data_size*2]#!\n",
        "training_list = labelled_filenames[testing_data_size*2:]#!\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvbvLdYtleRy",
        "outputId": "68a67487-a3a7-4e7f-9e8f-dd1a231c893e"
      },
      "source": [
        "len(training_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnwvvPrbleXV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBpHzl3NleZ2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHj6q8l5lecr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXNRm6vXe2LA"
      },
      "source": [
        "labelled_filenames = list(zip(filenames,labels))\n",
        "data_size = len(filenames)\n",
        "training_data_size = int(data_size * 0.7)\n",
        "random.shuffle(labelled_filenames)\n",
        "training_list = labelled_filenames[0:training_data_size]\n",
        "testing_list = labelled_filenames[training_data_size:]\n",
        "\n",
        "training_filenames, training_labels = zip(*training_list)\n",
        "testing_filenames, testing_labels = zip(*testing_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGSQNa85e2Nu",
        "outputId": "5c00d312-ccbc-45e3-e279-c1f777f92181"
      },
      "source": [
        "training_list[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/covid_data/COVID-19_Radiography_Dataset/Normal/Normal-3031.png', 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRM-0Eepe2Qf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NUkGG7be2Ss"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXtaKN28e2U9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ghe9F_zbEAzi"
      },
      "source": [
        "\n",
        "\n",
        "def build_training_tfrecord(training_filenames, training_labels):  \n",
        "    with tf.io.TFRecordWriter(train_tfrecord)as file_writer:\n",
        "        for filename, label in zip(training_filenames, training_labels):\n",
        "            image = open(filename, 'rb').read()\n",
        "            record_bytes = tf.train.Example(features=tf.train.Features(feature = {\n",
        "                'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])), \n",
        "                'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))  \n",
        "            })).SerializeToString()\n",
        "            file_writer.write(record_bytes)\n",
        "    \n",
        "\n",
        "def build_testing_tfrecord(test_filenames, testing_labels):  \n",
        "    with tf.io.TFRecordWriter(test_tfrecord)as file_writer:\n",
        "        for filename, label in zip(training_filenames, training_labels):\n",
        "            image = open(filename, 'rb').read()\n",
        "            record_bytes = tf.train.Example(features=tf.train.Features(feature = {\n",
        "                'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])), \n",
        "                'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label])) \n",
        "            })).SerializeToString()\n",
        "            file_writer.write(record_bytes)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09JeCJjWiwTG"
      },
      "source": [
        "#TO:DO\n",
        "#https://towardsdatascience.com/a-practical-guide-to-tfrecords-584536bc786c\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8ASQ5G6uktt"
      },
      "source": [
        "#https://gilberttanner.com/blog/tensorflow-js-crash-course"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8N40WQ97-Si"
      },
      "source": [
        "# VGG\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCio8hwG8BCJ"
      },
      "source": [
        "#https://www.kaggle.com/matheushms/covid-19-chest-x-ray-classificator\n",
        "#https://www.kaggle.com/bachrr/detecting-covid-19-in-x-ray-images-with-tensorflow\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models,layers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Input\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skIcCGj7B2e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7f281d6-cfc8-490d-fe99-a335701c7d49"
      },
      "source": [
        "base_model = VGG16(weights = 'imagenet', include_top=False, input_tensor=Input(shape=(224,224,3)))\n",
        "headmodel = base_model.output\n",
        "headmodel = AveragePooling2D(pool_size =(4, 4))(headmodel)\n",
        "headmodel = Flatten(name ='Flatten')(headmodel)\n",
        "headmodel = Dense(64, activation = 'relu')(headmodel)\n",
        "headmodel = Dropout(0.5)(headmodel)\n",
        "headmodel = Dense(1, activation = 'softmax')(headmodel)\n",
        "\n",
        "model = Model(inputs = base_model.input, outputs = headmodel)\n",
        "\n",
        "for layers in base_model.layers:\n",
        "    layers.trainable = False"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP8PrN4AjTaj"
      },
      "source": [
        "EPOCHS = 50\n",
        "#BS = 8\n",
        "LEARNING_RATE = 1e-5\n",
        "DECAY= LEARNING_RATE/EPOCHS\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    # optimizer = tf.keras.optimizers.RMSprop(lr=2e-5),\n",
        "     optimizer = tf.keras.optimizers.Nadam(learning_rate=LEARNING_RATE),\n",
        "    metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision(),\n",
        "             'acc']\n",
        ")\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYKD8d7n2y2K"
      },
      "source": [
        "#checkpoints_path = \"/content/img/model/checkpoints\"\n",
        "\n",
        "\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoints_path,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "#to avoid overfitting\n",
        "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=7)\n",
        "mcp_save = tf.keras.callbacks.ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVRnmEijyGVt",
        "outputId": "7b163324-e86e-457f-fe23-36748929dd13"
      },
      "source": [
        "callbacks = [model_checkpoint_callback,early,mcp_save]\n",
        "\n",
        "\n",
        "H = model.fit_generator(\n",
        "    train_flow,\n",
        "    steps_per_epoch = batch_size,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "    validation_data = val_flow,\n",
        "    validation_steps=batch_size,\n",
        "    verbose=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "18/18 [==============================] - 387s 21s/step - loss: 0.0000e+00 - recall: 1.0000 - precision: 0.7315 - acc: 0.7109 - val_loss: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.7159 - val_acc: 0.7685\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 325s 19s/step - loss: 0.0000e+00 - recall: 1.0000 - precision: 0.7314 - acc: 0.7034 - val_loss: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.7410 - val_acc: 0.7623\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 326s 19s/step - loss: 0.0000e+00 - recall: 1.0000 - precision: 0.7400 - acc: 0.6846 - val_loss: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.7359 - val_acc: 0.7253\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 325s 19s/step - loss: 0.0000e+00 - recall: 1.0000 - precision: 0.7355 - acc: 0.7377 - val_loss: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.7369 - val_acc: 0.7562\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 326s 19s/step - loss: 0.0000e+00 - recall: 1.0000 - precision: 0.7367 - acc: 0.7034 - val_loss: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.7376 - val_acc: 0.7654\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 328s 19s/step - loss: 0.0000e+00 - recall: 1.0000 - precision: 0.7383 - acc: 0.6910 - val_loss: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.7387 - val_acc: 0.7315\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 325s 19s/step - loss: 0.0000e+00 - recall: 1.0000 - precision: 0.7387 - acc: 0.7713 - val_loss: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.7390 - val_acc: 0.7130\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 325s 19s/step - loss: 0.0000e+00 - recall: 1.0000 - precision: 0.7367 - acc: 0.6982 - val_loss: 0.0000e+00 - val_recall: 1.0000 - val_precision: 0.7372 - val_acc: 0.7407\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBIn3GuG2pex",
        "outputId": "a52e3c6e-39ff-47e8-e280-ef1923131795"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "Flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 14,747,715\n",
            "Trainable params: 33,027\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCMUhFXt2pnH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cqWEy0n2pp-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCA4FYad2psU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96rm9LaDyGYV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz9Ja9SJyGbG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXxzZFHnyGdo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtMQr_rzyGgI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCQHdThhyGit"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OimJxm_2yGlK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9r_jcG7yGnv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBvcpP2ayGqF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dklaIZgKqAQ7"
      },
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoints_path,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max', \n",
        "    save_best_only=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R78evHSqA8C"
      },
      "source": [
        "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=7)\n",
        "mcp_save = tf.keras.callbacks.ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwlogELmB2jE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "86ad5457-e91c-4ddc-86dd-6d865c9fa5c4"
      },
      "source": [
        "\n",
        "with tf.device('/gpu:0'):\n",
        "    print(\"Training the model with gpu . . .\")\n",
        "    training = model.fit_generator(trainAug.flow(X_train, y_train, batch_size = BS),\n",
        "    steps_per_epoch=len(X_train) // BS, \n",
        "    validation_data=(X_test, y_test), \n",
        "    validation_steps=len(X_test) // BS, \n",
        "    epochs=100)\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training the model with gpu . . .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-0b92e30e2457>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/gpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training the model with gpu . . .\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainAug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trainAug' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc28dcEtnfP-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu0nxXivnfVe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_jh4WegnfYe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIKr3BHLnfbn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}